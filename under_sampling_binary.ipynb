{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T03:50:27.669639Z",
     "start_time": "2019-04-03T03:50:27.662657Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras_metrics\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "from keras.layers.convolutional import SeparableConv2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "\n",
    "\n",
    "import math\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T03:50:27.805277Z",
     "start_time": "2019-04-03T03:50:27.706540Z"
    }
   },
   "outputs": [],
   "source": [
    "df_metadata = pd.read_csv(filepath_or_buffer='..\\Images\\HAM10000_metadata.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T03:50:27.937651Z",
     "start_time": "2019-04-03T03:50:27.902745Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>akiec</th>\n",
       "      <td>327</td>\n",
       "      <td>327</td>\n",
       "      <td>327</td>\n",
       "      <td>327</td>\n",
       "      <td>327</td>\n",
       "      <td>327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bcc</th>\n",
       "      <td>514</td>\n",
       "      <td>514</td>\n",
       "      <td>514</td>\n",
       "      <td>514</td>\n",
       "      <td>514</td>\n",
       "      <td>514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bkl</th>\n",
       "      <td>1099</td>\n",
       "      <td>1099</td>\n",
       "      <td>1099</td>\n",
       "      <td>1089</td>\n",
       "      <td>1099</td>\n",
       "      <td>1099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df</th>\n",
       "      <td>115</td>\n",
       "      <td>115</td>\n",
       "      <td>115</td>\n",
       "      <td>115</td>\n",
       "      <td>115</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mel</th>\n",
       "      <td>1113</td>\n",
       "      <td>1113</td>\n",
       "      <td>1113</td>\n",
       "      <td>1111</td>\n",
       "      <td>1113</td>\n",
       "      <td>1113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nv</th>\n",
       "      <td>6705</td>\n",
       "      <td>6705</td>\n",
       "      <td>6705</td>\n",
       "      <td>6660</td>\n",
       "      <td>6705</td>\n",
       "      <td>6705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vasc</th>\n",
       "      <td>142</td>\n",
       "      <td>142</td>\n",
       "      <td>142</td>\n",
       "      <td>142</td>\n",
       "      <td>142</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       lesion_id  image_id  dx_type   age   sex  localization\n",
       "dx                                                           \n",
       "akiec        327       327      327   327   327           327\n",
       "bcc          514       514      514   514   514           514\n",
       "bkl         1099      1099     1099  1089  1099          1099\n",
       "df           115       115      115   115   115           115\n",
       "mel         1113      1113     1113  1111  1113          1113\n",
       "nv          6705      6705     6705  6660  6705          6705\n",
       "vasc         142       142      142   142   142           142"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metadata.groupby('dx').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T03:50:28.045364Z",
     "start_time": "2019-04-03T03:50:28.037385Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bkl', 'nv', 'df', 'mel', 'vasc', 'bcc', 'akiec'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking to see what the unique categories are\n",
    "df_metadata['dx'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T03:50:28.153074Z",
     "start_time": "2019-04-03T03:50:28.135123Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0027419.jpg</td>\n",
       "      <td>bkl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0025030.jpg</td>\n",
       "      <td>bkl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0026769.jpg</td>\n",
       "      <td>bkl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0025661.jpg</td>\n",
       "      <td>bkl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_0031633.jpg</td>\n",
       "      <td>bkl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           image_id   dx\n",
       "0  ISIC_0027419.jpg  bkl\n",
       "1  ISIC_0025030.jpg  bkl\n",
       "2  ISIC_0026769.jpg  bkl\n",
       "3  ISIC_0025661.jpg  bkl\n",
       "4  ISIC_0031633.jpg  bkl"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#keeping only relevant data, image filepath, and category\n",
    "df=df_metadata.loc[:,['image_id','dx']]\n",
    "\n",
    "#add .jpg extension to filepaths for every sample in image_id column\n",
    "df['image_id']=df['image_id'].apply(lambda x: x+'.jpg' )\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T03:50:28.288224Z",
     "start_time": "2019-04-03T03:50:28.272267Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dx\n",
       "akiec     327\n",
       "bcc       514\n",
       "bkl      1099\n",
       "df        115\n",
       "mel      1113\n",
       "nv       6705\n",
       "vasc      142\n",
       "Name: dx, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['dx'].groupby(df['dx']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T03:50:28.399210Z",
     "start_time": "2019-04-03T03:50:28.392229Z"
    }
   },
   "outputs": [],
   "source": [
    "#call bkl, mel and bcc cancer (1) and the rest not cancer (0)\n",
    "\n",
    "\n",
    "# WHY DOES THIS CODE WORK BUT THE FOLLOWING DOES!?!?!??!\n",
    "def binary_coder(sample):\n",
    "    if (sample =='mel') or (sample=='bcc') or (sample==\"akiec\"):\n",
    "        sample='1_cancer'\n",
    "    else:\n",
    "        sample='0_not_cancer'\n",
    "        \n",
    "    return sample\n",
    "    \n",
    "\n",
    "# def binary_coder(sample):\n",
    "#     if (sample =='mel') or (sample=='bcc') or (sample==\"akiec\"):\n",
    "#         sample='cancer'\n",
    "#         return sample\n",
    "\n",
    "#     else:\n",
    "#         sample='not cancer'\n",
    "#         return sample\n",
    "    \n",
    "df['dx'] = df['dx'].apply(binary_coder) \n",
    "\n",
    "\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T03:50:28.528543Z",
     "start_time": "2019-04-03T03:50:28.514580Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dx\n",
       "0_not_cancer    8061\n",
       "1_cancer        1954\n",
       "Name: dx, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['dx'].groupby(df['dx']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T03:50:28.633346Z",
     "start_time": "2019-04-03T03:50:28.626365Z"
    }
   },
   "outputs": [],
   "source": [
    "instances_of_cancer = len(df.loc[df['dx']=='cancer'])\n",
    "instances_of_not_cancer = len(df.loc[df['dx']=='not_cancer'])\n",
    "\n",
    "#ratio of cancer to not cancer\n",
    "\n",
    "# instances_of_not "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T03:50:28.759520Z",
     "start_time": "2019-04-03T03:50:28.742565Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dx\n",
       "0_not_cancer    8061\n",
       "1_cancer        1954\n",
       "Name: dx, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['dx'].groupby(df['dx']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T03:50:28.917618Z",
     "start_time": "2019-04-03T03:50:28.901659Z"
    }
   },
   "outputs": [],
   "source": [
    "balanced_df=df.drop(df[df['dx']=='0_not_cancer'].sample(frac=.7576).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T03:50:29.092149Z",
     "start_time": "2019-04-03T03:50:29.081177Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dx\n",
       "0_not_cancer    1954\n",
       "1_cancer        1954\n",
       "Name: dx, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df['dx'].groupby(balanced_df['dx']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T03:50:29.302593Z",
     "start_time": "2019-04-03T03:50:29.269678Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\petra\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test =train_test_split(balanced_df, train_size=.8, random_state =2, stratify=balanced_df['dx'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T03:50:29.528991Z",
     "start_time": "2019-04-03T03:50:29.523993Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3126, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T03:50:29.905942Z",
     "start_time": "2019-04-03T03:50:29.900950Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(782, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T03:50:30.704909Z",
     "start_time": "2019-04-03T03:50:30.132440Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3126 images belonging to 2 classes.\n",
      "Found 782 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "image_dimensions = (25,25)\n",
    "\n",
    "train_gen = ImageDataGenerator(rescale = 1./255, rotation_range = 45, horizontal_flip = True, vertical_flip = True)\n",
    "test_gen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "# train_gen = im_gen.flow_from_directory(directory = '..\\Images\\All_images_in_classes', target_size=(50,50), color_mode='rgb', class_mode = 'categorical', batch_size =100, subset ='training')\n",
    "# test_gen = im_gen.flow_from_directory(directory = '..\\Images\\All_images_in_classes', target_size=(50,50), color_mode='rgb', class_mode = 'categorical', batch_size =100, subset = 'validation')\n",
    "\n",
    "train_gen=train_gen.flow_from_dataframe(dataframe=df_train, directory ='..\\Images\\All_Images', x_col='image_id', y_col='dx',target_size=image_dimensions, color_mode='grayscale', class_mode='categorical', batch_size= batch_size)\n",
    "test_gen = test_gen.flow_from_dataframe(dataframe=df_test, directory ='..\\Images\\All_Images', x_col='image_id', y_col='dx',target_size=image_dimensions, color_mode='grayscale', class_mode='categorical', batch_size= batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T03:50:30.911358Z",
     "start_time": "2019-04-03T03:50:30.906371Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0_not_cancer': 0, '1_cancer': 1}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gen.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T03:50:31.102607Z",
     "start_time": "2019-04-03T03:50:31.090640Z"
    }
   },
   "outputs": [],
   "source": [
    "def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "    \n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T17:16:05.088026Z",
     "start_time": "2019-04-02T17:16:04.787188Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\petra\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 23, 23, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 23, 23, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 11, 11, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 9, 9, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 2, 2, 64)          18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 32,354\n",
      "Trainable params: 32,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# def recall(y_true, y_pred):\n",
    "#     return recall_score(y_true, y_pred, average = 'micro')\n",
    "input_into_first_layer = (25,25,1)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3),input_shape=input_into_first_layer))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3),activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2) ))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation ='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(64, activation ='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation ='softmax'))\n",
    "# model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['binary_accuracy',recall, f1])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T17:16:10.968837Z",
     "start_time": "2019-04-02T17:16:05.223649Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\petra\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-9b823f569f9c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m         \u001b[0mtrain_gen\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3126\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         epochs=2)\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;31m#         class_weight = {0:1,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[0;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m                                             class_weight=class_weight)\n\u001b[0m\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1217\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "        train_gen,\n",
    "        steps_per_epoch=3126,\n",
    "        epochs=2)\n",
    "#         class_weight = {0:1,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T03:37:34.845218Z",
     "start_time": "2019-04-02T03:37:23.573Z"
    }
   },
   "outputs": [],
   "source": [
    "#SWITCHING from clas_mode=binary loss = sparse_cat_crossE and etrics = binary to categorical leads to better results sparse leads to betet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T17:48:58.064946Z",
     "start_time": "2019-04-01T17:48:48.463552Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5745448469353454, 0.700767267466811, 0.700767267466811, 0.7007672269173595]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_generator(test_gen,steps =len(test_gen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration 2: Trying 1 node in the output with a sigmoid activation fucntion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class_mode= binary\n",
    "loss= binary_crossentropy\n",
    "1 sigmoid activation node in output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T18:03:50.971011Z",
     "start_time": "2019-04-01T18:03:50.774512Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3126 images belonging to 2 classes.\n",
      "Found 782 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "image_dimensions = (25,25)\n",
    "\n",
    "\n",
    "train_gen2 = ImageDataGenerator(rescale = 1./255, rotation_range = 45, horizontal_flip = True, vertical_flip = True)\n",
    "test_gen2 = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "# train_gen = im_gen.flow_from_directory(directory = '..\\Images\\All_images_in_classes', target_size=(50,50), color_mode='rgb', class_mode = 'categorical', batch_size =100, subset ='training')\n",
    "# test_gen = im_gen.flow_from_directory(directory = '..\\Images\\All_images_in_classes', target_size=(50,50), color_mode='rgb', class_mode = 'categorical', batch_size =100, subset = 'validation')\n",
    "\n",
    "train_gen2=train_gen2.flow_from_dataframe(dataframe=df_train, directory ='..\\Images\\All_Images', x_col='image_id', y_col='dx',target_size=image_dimensions, color_mode='grayscale', class_mode='binary', batch_size= batch_size)\n",
    "test_gen2= test_gen2.flow_from_dataframe(dataframe=df_test, directory ='..\\Images\\All_Images', x_col='image_id', y_col='dx',target_size=image_dimensions, color_mode='grayscale', class_mode='binary', batch_size= batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T18:03:51.869495Z",
     "start_time": "2019-04-01T18:03:51.664046Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 23, 23, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 23, 23, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 11, 11, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 9, 9, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 2, 2, 64)          18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 32,289\n",
      "Trainable params: 32,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "\n",
    "model2.add(Conv2D(32, (3, 3),input_shape=input_into_first_layer))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model2.add(Conv2D(32, (3, 3),activation = 'relu'))\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2) ))\n",
    "\n",
    "model2.add(Conv2D(64, (3, 3), activation ='relu'))\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model2.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model2.add(Dense(64, activation ='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "model2.add(Dense(1, activation ='sigmoid'))\n",
    "# model.add(Activation('softmax'))\n",
    "\n",
    "model2.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['binary_accuracy',recall,precision, f1])\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T18:17:40.226976Z",
     "start_time": "2019-04-01T18:03:53.522864Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "3126/3126 [==============================] - 407s 130ms/step - loss: 0.6693 - binary_accuracy: 0.5691 - recall: 0.5844 - precision: 0.4791 - f1: 0.4759\n",
      "Epoch 2/2\n",
      "3126/3126 [==============================] - 420s 134ms/step - loss: 0.5734 - binary_accuracy: 0.7062 - recall: 0.7331 - precision: 0.7012 - f1: 0.6857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21f2b000128>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit_generator(\n",
    "        train_gen2,\n",
    "        steps_per_epoch=3126,\n",
    "        epochs=2)\n",
    "#         class_weight = {0:1,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T20:07:37.344198Z",
     "start_time": "2019-03-22T20:07:33.665605Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5235555291175842,\n",
       " 0.7433333337306977,\n",
       " 0.6808730244636536,\n",
       " 0.7615873058636983,\n",
       " 0.6965946644544602]"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate_generator(test_gen2,steps =len(test_gen))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iteration Three"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class_mode=sparse\n",
    "loss=binary_crossentropy\n",
    "outut layer: 1 sigmoid activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T20:07:57.741925Z",
     "start_time": "2019-03-22T20:07:57.519484Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3126 images belonging to 2 classes.\n",
      "Found 782 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "image_dimensions = (25,25)\n",
    "\n",
    "train_gen3 = ImageDataGenerator(rescale = 1./255, rotation_range = 45, horizontal_flip = True, vertical_flip = True)\n",
    "test_gen3 = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "# train_gen = im_gen.flow_from_directory(directory = '..\\Images\\All_images_in_classes', target_size=(50,50), color_mode='rgb', class_mode = 'categorical', batch_size =100, subset ='training')\n",
    "# test_gen = im_gen.flow_from_directory(directory = '..\\Images\\All_images_in_classes', target_size=(50,50), color_mode='rgb', class_mode = 'categorical', batch_size =100, subset = 'validation')\n",
    "\n",
    "train_gen3=train_gen3.flow_from_dataframe(dataframe=df_train, directory ='..\\Images\\All_Images', x_col='image_id', y_col='dx',target_size=image_dimensions, color_mode='grayscale', class_mode='sparse', batch_size= batch_size)\n",
    "test_gen3= test_gen3.flow_from_dataframe(dataframe=df_test, directory ='..\\Images\\All_Images', x_col='image_id', y_col='dx',target_size=image_dimensions, color_mode='grayscale', class_mode='sparse', batch_size= batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T17:15:09.627615Z",
     "start_time": "2019-03-22T17:15:09.273155Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_21 (Conv2D)           (None, 23, 23, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 23, 23, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 11, 11, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 9, 9, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 2, 2, 64)          18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 32,289\n",
      "Trainable params: 32,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3 = Sequential()\n",
    "\n",
    "model3.add(Conv2D(32, (3, 3),input_shape=input_into_first_layer))\n",
    "model3.add(Activation('relu'))\n",
    "model3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model3.add(Conv2D(32, (3, 3),activation = 'relu'))\n",
    "model3.add(MaxPooling2D(pool_size=(2, 2) ))\n",
    "\n",
    "model3.add(Conv2D(64, (3, 3), activation ='relu'))\n",
    "model3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model3.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model3.add(Dense(64, activation ='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "model3.add(Dense(1, activation ='sigmoid'))\n",
    "# model.add(Activation('softmax'))\n",
    "\n",
    "model3.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['binary_accuracy',recall,precision, f1])\n",
    "\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T17:33:46.127109Z",
     "start_time": "2019-03-22T17:15:11.770651Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "3126/3126 [==============================] - 566s 181ms/step - loss: 0.6862 - binary_accuracy: 0.5283 - recall: 0.6376 - precision: 0.4381 - f1: 0.4771\n",
      "Epoch 2/2\n",
      "3126/3126 [==============================] - 548s 175ms/step - loss: 0.5943 - binary_accuracy: 0.6814 - recall: 0.6394 - precision: 0.7029 - f1: 0.6322\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e7ba3efdd8>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit_generator(\n",
    "        train_gen3,\n",
    "        steps_per_epoch=3126,\n",
    "        epochs=2)\n",
    "#         class_weight = {0:1,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T18:23:03.267434Z",
     "start_time": "2019-03-22T18:22:50.314445Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5498295507924941,\n",
       " 0.7365728889584846,\n",
       " 0.678129950600207,\n",
       " 0.7425658689130603,\n",
       " 0.6799075242579745]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#len(test_gen_3) * batch_size previously define is about the number of testing samples we have\n",
    "model3.evaluate_generator(test_gen3, steps = len(test_gen3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T18:29:48.756138Z",
     "start_time": "2019-03-22T18:29:48.752147Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cancer': 0, 'not cancer': 1}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gen3.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T18:22:04.961883Z",
     "start_time": "2019-03-22T18:22:04.958123Z"
    }
   },
   "source": [
    "# Iteration 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class_mode=binary\n",
    "loss=binary_crossentropy\n",
    "outut layer: 1 sigmoid activation\n",
    "class_weight = {0:1,\n",
    "                        1:1.5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T20:08:10.846974Z",
     "start_time": "2019-03-22T20:08:10.630554Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3126 images belonging to 2 classes.\n",
      "Found 782 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "image_dimensions = (25,25)\n",
    "\n",
    "train_gen4 = ImageDataGenerator(rescale = 1./255, rotation_range = 45, horizontal_flip = True, vertical_flip = True)\n",
    "test_gen4 = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "# train_gen = im_gen.flow_from_directory(directory = '..\\Images\\All_images_in_classes', target_size=(50,50), color_mode='rgb', class_mode = 'categorical', batch_size =100, subset ='training')\n",
    "# test_gen = im_gen.flow_from_directory(directory = '..\\Images\\All_images_in_classes', target_size=(50,50), color_mode='rgb', class_mode = 'categorical', batch_size =100, subset = 'validation')\n",
    "\n",
    "train_gen4=train_gen4.flow_from_dataframe(dataframe=df_train, directory ='..\\Images\\All_Images', x_col='image_id', y_col='dx',target_size=image_dimensions, color_mode='grayscale', class_mode='binary', batch_size= batch_size)\n",
    "test_gen4= test_gen4.flow_from_dataframe(dataframe=df_test, directory ='..\\Images\\All_Images', x_col='image_id', y_col='dx',target_size=image_dimensions, color_mode='grayscale', class_mode='binary', batch_size= batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T20:08:11.046954Z",
     "start_time": "2019-03-22T20:08:11.042004Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0_not_cancer': 0, '1_cancer': 1}"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gen4.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T20:08:18.331777Z",
     "start_time": "2019-03-22T20:08:18.078488Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_39 (Conv2D)           (None, 23, 23, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 23, 23, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_37 (MaxPooling (None, 11, 11, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 9, 9, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_38 (MaxPooling (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 2, 2, 64)          18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_39 (MaxPooling (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 32,289\n",
      "Trainable params: 32,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model4 = Sequential()\n",
    "\n",
    "model4.add(Conv2D(32, (3, 3),input_shape=input_into_first_layer))\n",
    "model4.add(Activation('relu'))\n",
    "model4.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model4.add(Conv2D(32, (3, 3),activation = 'relu'))\n",
    "model4.add(MaxPooling2D(pool_size=(2, 2) ))\n",
    "\n",
    "model4.add(Conv2D(64, (3, 3), activation ='relu'))\n",
    "model4.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model4.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model4.add(Dense(64, activation ='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "model4.add(Dense(1, activation ='sigmoid'))\n",
    "# model.add(Activation('softmax'))\n",
    "\n",
    "model4.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['binary_accuracy',recall,precision, f1])\n",
    "\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T20:22:57.801670Z",
     "start_time": "2019-03-22T20:08:52.132049Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "3126/3126 [==============================] - 422s 135ms/step - loss: 0.8136 - binary_accuracy: 0.5486 - recall: 0.9268 - precision: 0.5349 - f1: 0.6523\n",
      "Epoch 2/2\n",
      "3126/3126 [==============================] - 424s 136ms/step - loss: 0.7074 - binary_accuracy: 0.6843 - recall: 0.8366 - precision: 0.6494 - f1: 0.7067\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e7cc5dcc18>"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.fit_generator(\n",
    "        train_gen4,\n",
    "        steps_per_epoch=3126,\n",
    "        epochs=2,\n",
    "        class_weight = {0:1,\n",
    "                        1:1.5}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T20:24:26.438936Z",
     "start_time": "2019-03-22T20:24:16.650695Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5803747610820224,\n",
       " 0.6969309472062094,\n",
       " 0.8654853261035421,\n",
       " 0.6500172622292243,\n",
       " 0.7240466039503932]"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#len(test_gen_3) * batch_size previously define is about the number of testing samples we have\n",
    "model4.evaluate_generator(test_gen4, steps = len(test_gen4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class_mode=binary\n",
    "loss=binary_crossentropy\n",
    "outut layer: 1 sigmoid activation\n",
    "class_weight = {0:1,\n",
    "                        1:2.5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T21:59:36.962971Z",
     "start_time": "2019-04-01T21:59:36.762467Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3126 images belonging to 2 classes.\n",
      "Found 782 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "image_dimensions = (25,25)\n",
    "\n",
    "train_gen5 = ImageDataGenerator(rescale = 1./255, rotation_range = 45, horizontal_flip = True, vertical_flip = True)\n",
    "test_gen5 = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "# train_gen = im_gen.flow_from_directory(directory = '..\\Images\\All_images_in_classes', target_size=(50,50), color_mode='rgb', class_mode = 'categorical', batch_size =100, subset ='training')\n",
    "# test_gen = im_gen.flow_from_directory(directory = '..\\Images\\All_images_in_classes', target_size=(50,50), color_mode='rgb', class_mode = 'categorical', batch_size =100, subset = 'validation')\n",
    "\n",
    "train_gen5=train_gen5.flow_from_dataframe(dataframe=df_train, directory ='..\\Images\\All_Images', x_col='image_id', y_col='dx',target_size=image_dimensions, color_mode='grayscale', class_mode='binary', batch_size= batch_size)\n",
    "test_gen5= test_gen5.flow_from_dataframe(dataframe=df_test, directory ='..\\Images\\All_Images', x_col='image_id', y_col='dx',target_size=image_dimensions, color_mode='grayscale', class_mode='binary', batch_size= batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T21:59:37.951939Z",
     "start_time": "2019-04-01T21:59:37.946953Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0_not_cancer': 0, '1_cancer': 1}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gen5.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T21:59:39.372764Z",
     "start_time": "2019-04-01T21:59:39.142394Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 23, 23, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 23, 23, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 11, 11, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 9, 9, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 2, 2, 64)          18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 32,289\n",
      "Trainable params: 32,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model5 = Sequential()\n",
    "\n",
    "model5.add(Conv2D(32, (3, 3),input_shape=input_into_first_layer))\n",
    "model5.add(Activation('relu'))\n",
    "model5.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model5.add(Conv2D(32, (3, 3),activation = 'relu'))\n",
    "model5.add(MaxPooling2D(pool_size=(2, 2) ))\n",
    "\n",
    "model5.add(Conv2D(64, (3, 3), activation ='relu'))\n",
    "model5.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model5.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model5.add(Dense(64, activation ='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "model5.add(Dense(1, activation ='sigmoid'))\n",
    "# model.add(Activation('softmax'))\n",
    "\n",
    "model5.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['binary_accuracy',recall,precision, f1])\n",
    "\n",
    "model5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T22:14:06.115860Z",
     "start_time": "2019-04-01T21:59:40.838487Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "3126/3126 [==============================] - 418s 134ms/step - loss: 0.9940 - binary_accuracy: 0.5388 - recall: 0.9767 - precision: 0.5264 - f1: 0.6650\n",
      "Epoch 2/2\n",
      "3126/3126 [==============================] - 446s 143ms/step - loss: 0.8492 - binary_accuracy: 0.6674 - recall: 0.9285 - precision: 0.6159 - f1: 0.7215\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21f453c42e8>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5.fit_generator(\n",
    "        train_gen5,\n",
    "        steps_per_epoch=3126,\n",
    "        epochs=2,\n",
    "        class_weight = {0:1,\n",
    "                        1:2.5}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T22:14:39.075642Z",
     "start_time": "2019-04-01T22:14:29.722615Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7447367730881552,\n",
       " 0.6355498771914436,\n",
       " 0.9773576082780843,\n",
       " 0.5807859461821253,\n",
       " 0.7154763806658937]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#len(test_gen_3) * batch_size previously define is about the number of testing samples we have\n",
    "model5.evaluate_generator(test_gen5, steps = len(test_gen5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration 6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class_mode=binary\n",
    "loss=binary_crossentropy\n",
    "outut layer: 1 sigmoid activation\n",
    "class_weight = {0:1,\n",
    "                        1:2.5}\n",
    "increase epoch to 30                      \n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T18:18:13.176158Z",
     "start_time": "2019-04-01T18:18:12.951726Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3126 images belonging to 2 classes.\n",
      "Found 782 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "image_dimensions = (25,25)\n",
    "\n",
    "train_gen6 = ImageDataGenerator(rescale = 1./255, rotation_range = 45, horizontal_flip = True, vertical_flip = True)\n",
    "test_gen6 = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "# train_gen = im_gen.flow_from_directory(directory = '..\\Images\\All_images_in_classes', target_size=(50,50), color_mode='rgb', class_mode = 'categorical', batch_size =100, subset ='training')\n",
    "# test_gen = im_gen.flow_from_directory(directory = '..\\Images\\All_images_in_classes', target_size=(50,50), color_mode='rgb', class_mode = 'categorical', batch_size =100, subset = 'validation')\n",
    "\n",
    "train_gen6=train_gen6.flow_from_dataframe(dataframe=df_train, directory ='..\\Images\\All_Images', x_col='image_id', y_col='dx',target_size=image_dimensions, color_mode='grayscale', class_mode='binary', batch_size= batch_size)\n",
    "test_gen6= test_gen6.flow_from_dataframe(dataframe=df_test, directory ='..\\Images\\All_Images', x_col='image_id', y_col='dx',target_size=image_dimensions, color_mode='grayscale', class_mode='binary', batch_size= batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T18:18:14.619042Z",
     "start_time": "2019-04-01T18:18:14.614056Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0_not_cancer': 0, '1_cancer': 1}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gen6.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T18:18:16.258249Z",
     "start_time": "2019-04-01T18:18:16.013862Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 23, 23, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 23, 23, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 11, 11, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 9, 9, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 2, 2, 64)          18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 32,289\n",
      "Trainable params: 32,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model6 = Sequential()\n",
    "\n",
    "model6.add(Conv2D(32, (3, 3),input_shape=input_into_first_layer))\n",
    "model6.add(Activation('relu'))\n",
    "model6.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model6.add(Conv2D(32, (3, 3),activation = 'relu'))\n",
    "model6.add(MaxPooling2D(pool_size=(2, 2) ))\n",
    "\n",
    "model6.add(Conv2D(64, (3, 3), activation ='relu'))\n",
    "model6.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model6.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model6.add(Dense(64, activation ='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "model6.add(Dense(1, activation ='sigmoid'))\n",
    "# model.add(Activation('softmax'))\n",
    "\n",
    "model6.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['binary_accuracy',recall,precision, f1])\n",
    "\n",
    "model6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T21:53:16.255585Z",
     "start_time": "2019-04-01T18:21:41.806650Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "3126/3126 [==============================] - 423s 135ms/step - loss: 0.9106 - binary_accuracy: 0.6090 - recall: 0.9437 - precision: 0.5747 - f1: 0.6932\n",
      "Epoch 2/30\n",
      "3126/3126 [==============================] - 430s 137ms/step - loss: 0.8326 - binary_accuracy: 0.6803 - recall: 0.9222 - precision: 0.6255 - f1: 0.7261\n",
      "Epoch 3/30\n",
      "3126/3126 [==============================] - 426s 136ms/step - loss: 0.8105 - binary_accuracy: 0.6874 - recall: 0.9249 - precision: 0.6326 - f1: 0.7311\n",
      "Epoch 4/30\n",
      "3126/3126 [==============================] - 422s 135ms/step - loss: 0.7935 - binary_accuracy: 0.6991 - recall: 0.9245 - precision: 0.6420 - f1: 0.7395\n",
      "Epoch 5/30\n",
      "3126/3126 [==============================] - 420s 134ms/step - loss: 0.7758 - binary_accuracy: 0.7082 - recall: 0.9282 - precision: 0.6486 - f1: 0.7458\n",
      "Epoch 6/30\n",
      "3126/3126 [==============================] - 414s 133ms/step - loss: 0.7700 - binary_accuracy: 0.7124 - recall: 0.9267 - precision: 0.6519 - f1: 0.7475\n",
      "Epoch 7/30\n",
      "3126/3126 [==============================] - 417s 133ms/step - loss: 0.7615 - binary_accuracy: 0.7175 - recall: 0.9310 - precision: 0.6548 - f1: 0.7512\n",
      "Epoch 8/30\n",
      "3126/3126 [==============================] - 418s 134ms/step - loss: 0.7513 - binary_accuracy: 0.7232 - recall: 0.9297 - precision: 0.6608 - f1: 0.7553\n",
      "Epoch 9/30\n",
      "3126/3126 [==============================] - 434s 139ms/step - loss: 0.7508 - binary_accuracy: 0.7198 - recall: 0.9284 - precision: 0.6575 - f1: 0.7525\n",
      "Epoch 10/30\n",
      "3126/3126 [==============================] - 431s 138ms/step - loss: 0.7390 - binary_accuracy: 0.7265 - recall: 0.9322 - precision: 0.6630 - f1: 0.7583\n",
      "Epoch 11/30\n",
      "3126/3126 [==============================] - 418s 134ms/step - loss: 0.7344 - binary_accuracy: 0.7276 - recall: 0.9304 - precision: 0.6634 - f1: 0.7571\n",
      "Epoch 12/30\n",
      "3126/3126 [==============================] - 419s 134ms/step - loss: 0.7258 - binary_accuracy: 0.7290 - recall: 0.9327 - precision: 0.6645 - f1: 0.7591\n",
      "Epoch 13/30\n",
      "3126/3126 [==============================] - 421s 135ms/step - loss: 0.7210 - binary_accuracy: 0.7303 - recall: 0.9313 - precision: 0.6660 - f1: 0.7595\n",
      "Epoch 14/30\n",
      "3126/3126 [==============================] - 420s 134ms/step - loss: 0.7148 - binary_accuracy: 0.7332 - recall: 0.9305 - precision: 0.6683 - f1: 0.7609\n",
      "Epoch 15/30\n",
      "3126/3126 [==============================] - 420s 134ms/step - loss: 0.7129 - binary_accuracy: 0.7348 - recall: 0.9341 - precision: 0.6690 - f1: 0.7633\n",
      "Epoch 16/30\n",
      "3126/3126 [==============================] - 419s 134ms/step - loss: 0.7001 - binary_accuracy: 0.7380 - recall: 0.9370 - precision: 0.6717 - f1: 0.7657\n",
      "Epoch 17/30\n",
      "3126/3126 [==============================] - 415s 133ms/step - loss: 0.7034 - binary_accuracy: 0.7383 - recall: 0.9369 - precision: 0.6723 - f1: 0.7662\n",
      "Epoch 18/30\n",
      "3126/3126 [==============================] - 411s 132ms/step - loss: 0.6951 - binary_accuracy: 0.7410 - recall: 0.9341 - precision: 0.6746 - f1: 0.7665\n",
      "Epoch 19/30\n",
      "3126/3126 [==============================] - 421s 135ms/step - loss: 0.6891 - binary_accuracy: 0.7454 - recall: 0.9391 - precision: 0.6805 - f1: 0.7722\n",
      "Epoch 20/30\n",
      "3126/3126 [==============================] - 415s 133ms/step - loss: 0.6831 - binary_accuracy: 0.7456 - recall: 0.9391 - precision: 0.6771 - f1: 0.7703\n",
      "Epoch 21/30\n",
      "3126/3126 [==============================] - 420s 134ms/step - loss: 0.6750 - binary_accuracy: 0.7504 - recall: 0.9400 - precision: 0.6831 - f1: 0.7752\n",
      "Epoch 22/30\n",
      "3126/3126 [==============================] - 416s 133ms/step - loss: 0.6761 - binary_accuracy: 0.7472 - recall: 0.9400 - precision: 0.6793 - f1: 0.7718\n",
      "Epoch 23/30\n",
      "3126/3126 [==============================] - 423s 135ms/step - loss: 0.6669 - binary_accuracy: 0.7509 - recall: 0.9394 - precision: 0.6831 - f1: 0.7752\n",
      "Epoch 24/30\n",
      "3126/3126 [==============================] - 420s 134ms/step - loss: 0.6611 - binary_accuracy: 0.7532 - recall: 0.9415 - precision: 0.6862 - f1: 0.7775\n",
      "Epoch 25/30\n",
      "3126/3126 [==============================] - 414s 132ms/step - loss: 0.6585 - binary_accuracy: 0.7532 - recall: 0.9453 - precision: 0.6841 - f1: 0.7779\n",
      "Epoch 26/30\n",
      "3126/3126 [==============================] - 442s 141ms/step - loss: 0.6544 - binary_accuracy: 0.7551 - recall: 0.9428 - precision: 0.6854 - f1: 0.7779\n",
      "Epoch 27/30\n",
      "3126/3126 [==============================] - 450s 144ms/step - loss: 0.6514 - binary_accuracy: 0.7570 - recall: 0.9415 - precision: 0.6880 - f1: 0.7792\n",
      "Epoch 28/30\n",
      "3126/3126 [==============================] - 433s 139ms/step - loss: 0.6493 - binary_accuracy: 0.7587 - recall: 0.9434 - precision: 0.6912 - f1: 0.7824\n",
      "Epoch 29/30\n",
      "3126/3126 [==============================] - 429s 137ms/step - loss: 0.6439 - binary_accuracy: 0.7626 - recall: 0.9403 - precision: 0.6936 - f1: 0.7830\n",
      "Epoch 30/30\n",
      "3126/3126 [==============================] - 433s 138ms/step - loss: 0.6343 - binary_accuracy: 0.7661 - recall: 0.9443 - precision: 0.6980 - f1: 0.7873\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21f453afc88>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model6.fit_generator(\n",
    "        train_gen6,\n",
    "        steps_per_epoch=3126,\n",
    "        epochs=30,\n",
    "        class_weight = {0:1,\n",
    "                        1:2.5}\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T21:58:43.533142Z",
     "start_time": "2019-04-01T21:58:34.492236Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7833812721168903,\n",
       " 0.6867007717604527,\n",
       " 0.9404152965606631,\n",
       " 0.623609597878078,\n",
       " 0.7389177395712079]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model6.evaluate_generator(test_gen6, steps = len(test_gen6))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class_mode=binary\n",
    "loss=binary_crossentropy\n",
    "outut layer: 1 sigmoid activation\n",
    "class_weight = {0:1,\n",
    "                        1:2.5}\n",
    "epoch 10\n",
    "100 x 100 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T22:24:19.532109Z",
     "start_time": "2019-04-01T22:24:19.246870Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3126 images belonging to 2 classes.\n",
      "Found 782 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "image_dimensions = (100,100)\n",
    "input_into_first_layer = (100,100,1)\n",
    "\n",
    "\n",
    "train_gen7 = ImageDataGenerator(rescale = 1./255, rotation_range = 45, horizontal_flip = True, vertical_flip = True)\n",
    "test_gen7 = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "# train_gen = im_gen.flow_from_directory(directory = '..\\Images\\All_images_in_classes', target_size=(50,50), color_mode='rgb', class_mode = 'categorical', batch_size =100, subset ='training')\n",
    "# test_gen = im_gen.flow_from_directory(directory = '..\\Images\\All_images_in_classes', target_size=(50,50), color_mode='rgb', class_mode = 'categorical', batch_size =100, subset = 'validation')\n",
    "\n",
    "train_gen7=train_gen7.flow_from_dataframe(dataframe=df_train, directory ='..\\Images\\All_Images', x_col='image_id', y_col='dx',target_size=image_dimensions, color_mode='grayscale', class_mode='binary', batch_size= batch_size)\n",
    "test_gen7= test_gen7.flow_from_dataframe(dataframe=df_test, directory ='..\\Images\\All_Images', x_col='image_id', y_col='dx',target_size=image_dimensions, color_mode='grayscale', class_mode='binary', batch_size= batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T22:24:19.574993Z",
     "start_time": "2019-04-01T22:24:19.570006Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0_not_cancer': 0, '1_cancer': 1}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gen7.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T22:24:20.121746Z",
     "start_time": "2019-04-01T22:24:19.773677Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_31 (Conv2D)           (None, 98, 98, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 98, 98, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling (None, 49, 49, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 47, 47, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_32 (MaxPooling (None, 23, 23, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 21, 21, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_33 (MaxPooling (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 64)                409664    \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 437,793\n",
      "Trainable params: 437,793\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model7 = Sequential()\n",
    "\n",
    "model7.add(Conv2D(32, (3, 3),input_shape=input_into_first_layer))\n",
    "model7.add(Activation('relu'))\n",
    "model7.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model7.add(Conv2D(32, (3, 3),activation = 'relu'))\n",
    "model7.add(MaxPooling2D(pool_size=(2, 2) ))\n",
    "\n",
    "model7.add(Conv2D(64, (3, 3), activation ='relu'))\n",
    "model7.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model7.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model7.add(Dense(64, activation ='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "model7.add(Dense(1, activation ='sigmoid'))\n",
    "# model.add(Activation('softmax'))\n",
    "\n",
    "model7.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['binary_accuracy',recall,precision, f1])\n",
    "\n",
    "model7.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T23:59:10.007919Z",
     "start_time": "2019-04-01T22:24:20.162638Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3126/3126 [==============================] - 452s 145ms/step - loss: 0.9512 - binary_accuracy: 0.5595 - recall: 0.9705 - precision: 0.5387 - f1: 0.6736\n",
      "Epoch 2/10\n",
      "3126/3126 [==============================] - 441s 141ms/step - loss: 0.8145 - binary_accuracy: 0.6963 - recall: 0.9226 - precision: 0.6401 - f1: 0.7367\n",
      "Epoch 3/10\n",
      "3126/3126 [==============================] - 444s 142ms/step - loss: 0.7666 - binary_accuracy: 0.7157 - recall: 0.9316 - precision: 0.6533 - f1: 0.7505\n",
      "Epoch 4/10\n",
      "3126/3126 [==============================] - 498s 159ms/step - loss: 0.7436 - binary_accuracy: 0.7268 - recall: 0.9338 - precision: 0.6638 - f1: 0.7590\n",
      "Epoch 5/10\n",
      "3126/3126 [==============================] - 842s 269ms/step - loss: 0.7182 - binary_accuracy: 0.7394 - recall: 0.9390 - precision: 0.6725 - f1: 0.7676\n",
      "Epoch 6/10\n",
      "3126/3126 [==============================] - 567s 182ms/step - loss: 0.7030 - binary_accuracy: 0.7443 - recall: 0.9384 - precision: 0.6784 - f1: 0.7715\n",
      "Epoch 7/10\n",
      "3126/3126 [==============================] - 569s 182ms/step - loss: 0.6877 - binary_accuracy: 0.7491 - recall: 0.9412 - precision: 0.6824 - f1: 0.7750\n",
      "Epoch 8/10\n",
      "3126/3126 [==============================] - 609s 195ms/step - loss: 0.6710 - binary_accuracy: 0.7566 - recall: 0.9416 - precision: 0.6873 - f1: 0.7786\n",
      "Epoch 9/10\n",
      "3126/3126 [==============================] - 630s 202ms/step - loss: 0.6556 - binary_accuracy: 0.7625 - recall: 0.9459 - precision: 0.6934 - f1: 0.7841\n",
      "Epoch 10/10\n",
      "3126/3126 [==============================] - 636s 203ms/step - loss: 0.6321 - binary_accuracy: 0.7738 - recall: 0.9478 - precision: 0.7042 - f1: 0.7927\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21f4921b5f8>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model7.fit_generator(\n",
    "        train_gen7,\n",
    "        steps_per_epoch=3126,\n",
    "        epochs=10,\n",
    "        class_weight = {0:1,\n",
    "                        1:2.5}\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T00:25:02.257304Z",
     "start_time": "2019-04-02T00:24:50.627946Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.688211403291701,\n",
       " 0.7161125312833225,\n",
       " 0.9497929608730404,\n",
       " 0.6471298748193799,\n",
       " 0.7571639774553002]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model7.evaluate_generator(test_gen7, steps = len(test_gen7))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class_mode=binary\n",
    "loss=binary_crossentropy\n",
    "outut layer: 1 sigmoid activation\n",
    "class_weight = {0:1,\n",
    "                        1:2.5}\n",
    "epoch 8\n",
    "150 x 150 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T03:37:53.658350Z",
     "start_time": "2019-04-02T03:37:53.381091Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3126 images belonging to 2 classes.\n",
      "Found 782 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "image_dimensions = (150,150)\n",
    "input_into_first_layer = (150,150,1)\n",
    "\n",
    "\n",
    "train_gen8 = ImageDataGenerator(rescale = 1./255, rotation_range = 45, horizontal_flip = True, vertical_flip = True)\n",
    "test_gen8 = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "# train_gen = im_gen.flow_from_directory(directory = '..\\Images\\All_images_in_classes', target_size=(50,50), color_mode='rgb', class_mode = 'categorical', batch_size =100, subset ='training')\n",
    "# test_gen = im_gen.flow_from_directory(directory = '..\\Images\\All_images_in_classes', target_size=(50,50), color_mode='rgb', class_mode = 'categorical', batch_size =100, subset = 'validation')\n",
    "\n",
    "train_gen8=train_gen8.flow_from_dataframe(dataframe=df_train, directory ='..\\Images\\All_Images', x_col='image_id', y_col='dx',target_size=image_dimensions, color_mode='grayscale', class_mode='binary', batch_size= batch_size)\n",
    "test_gen8= test_gen8.flow_from_dataframe(dataframe=df_test, directory ='..\\Images\\All_Images', x_col='image_id', y_col='dx',target_size=image_dimensions, color_mode='grayscale', class_mode='binary', batch_size= batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T03:37:54.079111Z",
     "start_time": "2019-04-02T03:37:54.066147Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0_not_cancer': 0, '1_cancer': 1}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gen8.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T03:37:54.737351Z",
     "start_time": "2019-04-02T03:37:54.378311Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 148, 148, 32)      320       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 148, 148, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 72, 72, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 36, 36, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 34, 34, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 17, 17, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 18496)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                1183808   \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 1,211,937\n",
      "Trainable params: 1,211,937\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model8 = Sequential()\n",
    "\n",
    "model8.add(Conv2D(32, (3, 3),input_shape=input_into_first_layer))\n",
    "model8.add(Activation('relu'))\n",
    "model8.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model8.add(Conv2D(32, (3, 3),activation = 'relu'))\n",
    "model8.add(MaxPooling2D(pool_size=(2, 2) ))\n",
    "\n",
    "model8.add(Conv2D(64, (3, 3), activation ='relu'))\n",
    "model8.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model8.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model8.add(Dense(64, activation ='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "model8.add(Dense(1, activation ='sigmoid'))\n",
    "# model.add(Activation('softmax'))\n",
    "\n",
    "model8.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['binary_accuracy',recall,precision, f1])\n",
    "\n",
    "model8.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T04:41:07.620999Z",
     "start_time": "2019-04-02T03:37:54.872989Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "3126/3126 [==============================] - 479s 153ms/step - loss: 1.0081 - binary_accuracy: 0.5047 - recall: 0.9971 - precision: 0.5028 - f1: 0.6531\n",
      "Epoch 2/8\n",
      "3126/3126 [==============================] - 471s 151ms/step - loss: 0.8720 - binary_accuracy: 0.6472 - recall: 0.9363 - precision: 0.6004 - f1: 0.7114\n",
      "Epoch 3/8\n",
      "3126/3126 [==============================] - 471s 151ms/step - loss: 0.7657 - binary_accuracy: 0.7182 - recall: 0.9334 - precision: 0.6555 - f1: 0.7526\n",
      "Epoch 4/8\n",
      "3126/3126 [==============================] - 472s 151ms/step - loss: 0.7203 - binary_accuracy: 0.7361 - recall: 0.9384 - precision: 0.6703 - f1: 0.7657\n",
      "Epoch 5/8\n",
      "3126/3126 [==============================] - 476s 152ms/step - loss: 0.6789 - binary_accuracy: 0.7532 - recall: 0.9406 - precision: 0.6865 - f1: 0.7780\n",
      "Epoch 6/8\n",
      "3126/3126 [==============================] - 475s 152ms/step - loss: 0.6464 - binary_accuracy: 0.7692 - recall: 0.9432 - precision: 0.7007 - f1: 0.7885\n",
      "Epoch 7/8\n",
      "3126/3126 [==============================] - 474s 152ms/step - loss: 0.6193 - binary_accuracy: 0.7796 - recall: 0.9415 - precision: 0.7127 - f1: 0.7953\n",
      "Epoch 8/8\n",
      "3126/3126 [==============================] - 474s 152ms/step - loss: 0.5852 - binary_accuracy: 0.7922 - recall: 0.9448 - precision: 0.7249 - f1: 0.8055\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1db9dc34358>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model8.fit_generator(\n",
    "        train_gen8,\n",
    "        steps_per_epoch=3126,\n",
    "        epochs=8,\n",
    "        class_weight = {0:1,\n",
    "                        1:2.5}\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T05:36:26.328445Z",
     "start_time": "2019-04-02T05:36:16.821540Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7003274725754852,\n",
       " 0.7212276231602329,\n",
       " 0.9380201357404899,\n",
       " 0.661607406099739,\n",
       " 0.7611076059701193]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model8.evaluate_generator(test_gen8, steps = len(test_gen8))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration 9\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class_mode=binary\n",
    "loss=binary_crossentropy\n",
    "outut layer: 1 sigmoid activation\n",
    "class_weight = {0:1,\n",
    "                        1:2.5}\n",
    "epoch 10\n",
    "150 x 1500 images\n",
    "\n",
    "Architecture from: https://www.pyimagesearch.com/2019/02/18/breast-cancer-classification-with-keras-and-deep-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T17:17:40.054910Z",
     "start_time": "2019-04-02T17:17:39.708178Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3126 images belonging to 2 classes.\n",
      "Found 782 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "image_dimensions = (150,150)\n",
    "input_into_first_layer = (150,150,1)\n",
    "\n",
    "\n",
    "train_gen9 = ImageDataGenerator(rescale = 1./255, rotation_range = 45, horizontal_flip = True, vertical_flip = True)\n",
    "test_gen9 = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "# train_gen = im_gen.flow_from_directory(directory = '..\\Images\\All_images_in_classes', target_size=(50,50), color_mode='rgb', class_mode = 'categorical', batch_size =100, subset ='training')\n",
    "# test_gen = im_gen.flow_from_directory(directory = '..\\Images\\All_images_in_classes', target_size=(50,50), color_mode='rgb', class_mode = 'categorical', batch_size =100, subset = 'validation')\n",
    "\n",
    "train_gen9=train_gen9.flow_from_dataframe(dataframe=df_train, directory ='..\\Images\\All_Images', x_col='image_id', y_col='dx',target_size=image_dimensions, color_mode='grayscale', class_mode='binary', batch_size= batch_size)\n",
    "test_gen9= test_gen9.flow_from_dataframe(dataframe=df_test, directory ='..\\Images\\All_Images', x_col='image_id', y_col='dx',target_size=image_dimensions, color_mode='grayscale', class_mode='binary', batch_size= batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T17:17:40.224789Z",
     "start_time": "2019-04-02T17:17:40.216930Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0_not_cancer': 0, '1_cancer': 1}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gen9.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T17:18:27.183408Z",
     "start_time": "2019-04-02T17:18:24.677488Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\petra\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "separable_conv2d_3 (Separabl (None, 150, 150, 32)      73        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 150, 150, 32)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 150, 150, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 75, 75, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 75, 75, 32)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_4 (Separabl (None, 75, 75, 64)        2400      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 75, 75, 64)        256       \n",
      "_________________________________________________________________\n",
      "separable_conv2d_5 (Separabl (None, 75, 75, 64)        4736      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 75, 75, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 37, 37, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 37, 37, 64)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_6 (Separabl (None, 37, 37, 128)       8896      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 37, 37, 128)       512       \n",
      "_________________________________________________________________\n",
      "separable_conv2d_7 (Separabl (None, 37, 37, 128)       17664     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 37, 37, 128)       512       \n",
      "_________________________________________________________________\n",
      "separable_conv2d_8 (Separabl (None, 37, 37, 128)       17664     \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 37, 37, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 18, 18, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 18, 18, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 41472)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               10617088  \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 10,671,978\n",
      "Trainable params: 10,670,378\n",
      "Non-trainable params: 1,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# model9.add(Conv2D(32, (3, 3),input_shape=input_into_first_layer))\n",
    "# model9.add(Activation('relu'))\n",
    "# model9.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# model9.add(Conv2D(32, (3, 3),activation = 'relu'))\n",
    "# model9.add(MaxPooling2D(pool_size=(2, 2) ))\n",
    "\n",
    "# model9.add(Conv2D(64, (3, 3), activation ='relu'))\n",
    "# model9.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# model9.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "# model9.add(Dense(64, activation ='relu'))\n",
    "# # model.add(Dropout(0.5))\n",
    "# model9.add(Dense(1, activation ='sigmoid'))\n",
    "\n",
    "# model9.compile(loss='binary_crossentropy',\n",
    "#               optimizer='adam',\n",
    "#               metrics=['binary_accuracy',recall,precision, f1])\n",
    "\n",
    "# model9.summary()\n",
    "\n",
    "# CONV => RELU => POOL\n",
    "chanDim = -1\n",
    "\n",
    "model9 = Sequential()\n",
    "\n",
    "model9.add(SeparableConv2D(32, (3, 3), padding=\"same\",\n",
    "input_shape=input_into_first_layer))\n",
    "model9.add(Activation(\"relu\"))\n",
    "model9.add(BatchNormalization(axis=chanDim))\n",
    "model9.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model9.add(Dropout(0.25))\n",
    " \n",
    "# (CONV => RELU => POOL) * 2\n",
    "model9.add(SeparableConv2D(64, (3, 3), padding=\"same\"))\n",
    "model9.add(Activation(\"relu\"))\n",
    "model9.add(BatchNormalization(axis=chanDim))\n",
    "model9.add(SeparableConv2D(64, (3, 3), padding=\"same\"))\n",
    "model9.add(Activation(\"relu\"))\n",
    "model9.add(BatchNormalization(axis=chanDim))\n",
    "model9.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model9.add(Dropout(0.25))\n",
    " \n",
    "# (CONV => RELU => POOL) * 3\n",
    "model9.add(SeparableConv2D(128, (3, 3), padding=\"same\"))\n",
    "model9.add(Activation(\"relu\"))\n",
    "model9.add(BatchNormalization(axis=chanDim))\n",
    "model9.add(SeparableConv2D(128, (3, 3), padding=\"same\"))\n",
    "model9.add(Activation(\"relu\"))\n",
    "model9.add(BatchNormalization(axis=chanDim))\n",
    "model9.add(SeparableConv2D(128, (3, 3), padding=\"same\"))\n",
    "model9.add(Activation(\"relu\"))\n",
    "model9.add(BatchNormalization(axis=chanDim))\n",
    "model9.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model9.add(Dropout(0.25))\n",
    "\n",
    "model9.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model9.add(Dense(256, activation ='relu'))\n",
    "model9.add(BatchNormalization())\n",
    "\n",
    "model9.add(Dropout(0.5))\n",
    "model9.add(Dense(1, activation ='sigmoid'))\n",
    "# model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "model9.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['binary_accuracy',recall,precision, f1])\n",
    "\n",
    "model9.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T18:26:32.693138Z",
     "start_time": "2019-04-02T17:18:33.453609Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "3126/3126 [==============================] - 648s 207ms/step - loss: 1.0004 - binary_accuracy: 0.6023 - recall: 0.8813 - precision: 0.5710 - f1: 0.6731\n",
      "Epoch 2/8\n",
      "3126/3126 [==============================] - 521s 167ms/step - loss: 0.9057 - binary_accuracy: 0.6359 - recall: 0.9145 - precision: 0.5930 - f1: 0.6998\n",
      "Epoch 3/8\n",
      "3126/3126 [==============================] - 490s 157ms/step - loss: 0.8760 - binary_accuracy: 0.6525 - recall: 0.9229 - precision: 0.6058 - f1: 0.7109\n",
      "Epoch 4/8\n",
      "3126/3126 [==============================] - 502s 160ms/step - loss: 0.8590 - binary_accuracy: 0.6669 - recall: 0.9215 - precision: 0.6161 - f1: 0.7190\n",
      "Epoch 5/8\n",
      "3126/3126 [==============================] - 481s 154ms/step - loss: 0.8712 - binary_accuracy: 0.6587 - recall: 0.9199 - precision: 0.6101 - f1: 0.7132\n",
      "Epoch 6/8\n",
      "3126/3126 [==============================] - 477s 153ms/step - loss: 0.8512 - binary_accuracy: 0.6701 - recall: 0.9253 - precision: 0.6184 - f1: 0.7221\n",
      "Epoch 7/8\n",
      "3126/3126 [==============================] - 477s 153ms/step - loss: 0.8465 - binary_accuracy: 0.6768 - recall: 0.9255 - precision: 0.6231 - f1: 0.7258\n",
      "Epoch 8/8\n",
      "3126/3126 [==============================] - 479s 153ms/step - loss: 0.8396 - binary_accuracy: 0.6795 - recall: 0.9259 - precision: 0.6258 - f1: 0.7277\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f0c1885048>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model9.fit_generator(\n",
    "        train_gen9,\n",
    "        steps_per_epoch=3126,\n",
    "        epochs=8,\n",
    "        class_weight = {0:1,\n",
    "                        1:2.5}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T22:04:08.139689Z",
     "start_time": "2019-04-02T22:03:56.250575Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5799204055839182,\n",
       " 0.6879795444438525,\n",
       " 0.6593746256340495,\n",
       " 0.7024418532543475,\n",
       " 0.6553505035617467]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model9.evaluate_generator(test_gen9, steps = len(test_gen9))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T22:40:43.085433Z",
     "start_time": "2019-04-02T22:39:38.236574Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5833175691060355,\n",
       " 0.6823416530552081,\n",
       " 0.5933606064594181,\n",
       " 0.7223555149363923,\n",
       " 0.6207036236521531]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model9.evaluate_generator(train_gen9, steps = len(train_gen9))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class_mode=binary\n",
    "loss=binary_crossentropy\n",
    "outut layer: 1 sigmoid activation\n",
    "class_weight = {0:1,\n",
    "                        1:3.5}\n",
    "epoch 20\n",
    "150 x 150 images\n",
    "\n",
    "Architecture from: https://www.pyimagesearch.com/2019/02/18/breast-cancer-classification-with-keras-and-deep-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T18:41:40.510857Z",
     "start_time": "2019-04-02T18:41:40.296417Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3126 images belonging to 2 classes.\n",
      "Found 782 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "image_dimensions = (150,150)\n",
    "input_into_first_layer = (150,150,1)\n",
    "\n",
    "\n",
    "train_gen10 = ImageDataGenerator(rescale = 1./255, rotation_range = 45, horizontal_flip = True, vertical_flip = True)\n",
    "test_gen10 = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "# train_gen = im_gen.flow_from_directory(directory = '..\\Images\\All_images_in_classes', target_size=(50,50), color_mode='rgb', class_mode = 'categorical', batch_size =100, subset ='training')\n",
    "# test_gen = im_gen.flow_from_directory(directory = '..\\Images\\All_images_in_classes', target_size=(50,50), color_mode='rgb', class_mode = 'categorical', batch_size =100, subset = 'validation')\n",
    "\n",
    "train_gen10=train_gen10.flow_from_dataframe(dataframe=df_train, directory ='..\\Images\\All_Images', x_col='image_id', y_col='dx',target_size=image_dimensions, color_mode='grayscale', class_mode='binary', batch_size= batch_size)\n",
    "test_gen10= test_gen10.flow_from_dataframe(dataframe=df_test, directory ='..\\Images\\All_Images', x_col='image_id', y_col='dx',target_size=image_dimensions, color_mode='grayscale', class_mode='binary', batch_size= batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T18:41:41.899082Z",
     "start_time": "2019-04-02T18:41:41.894095Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0_not_cancer': 0, '1_cancer': 1}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gen10.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T18:41:46.846411Z",
     "start_time": "2019-04-02T18:41:45.459988Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "separable_conv2d_9 (Separabl (None, 150, 150, 32)      73        \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 150, 150, 32)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 150, 150, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 75, 75, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 75, 75, 32)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_10 (Separab (None, 75, 75, 64)        2400      \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 75, 75, 64)        256       \n",
      "_________________________________________________________________\n",
      "separable_conv2d_11 (Separab (None, 75, 75, 64)        4736      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 75, 75, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 37, 37, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 37, 37, 64)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_12 (Separab (None, 37, 37, 128)       8896      \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 37, 37, 128)       512       \n",
      "_________________________________________________________________\n",
      "separable_conv2d_13 (Separab (None, 37, 37, 128)       17664     \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 37, 37, 128)       512       \n",
      "_________________________________________________________________\n",
      "separable_conv2d_14 (Separab (None, 37, 37, 128)       17664     \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 37, 37, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 18, 18, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 18, 18, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 41472)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               10617088  \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 10,671,978\n",
      "Trainable params: 10,670,378\n",
      "Non-trainable params: 1,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# model9.add(Conv2D(32, (3, 3),input_shape=input_into_first_layer))\n",
    "# model9.add(Activation('relu'))\n",
    "# model9.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# model9.add(Conv2D(32, (3, 3),activation = 'relu'))\n",
    "# model9.add(MaxPooling2D(pool_size=(2, 2) ))\n",
    "\n",
    "# model9.add(Conv2D(64, (3, 3), activation ='relu'))\n",
    "# model9.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# model9.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "# model9.add(Dense(64, activation ='relu'))\n",
    "# # model.add(Dropout(0.5))\n",
    "# model9.add(Dense(1, activation ='sigmoid'))\n",
    "\n",
    "# model9.compile(loss='binary_crossentropy',\n",
    "#               optimizer='adam',\n",
    "#               metrics=['binary_accuracy',recall,precision, f1])\n",
    "\n",
    "# model9.summary()\n",
    "\n",
    "# CONV => RELU => POOL\n",
    "chanDim = -1\n",
    "\n",
    "model10 = Sequential()\n",
    "\n",
    "model10.add(SeparableConv2D(32, (3, 3), padding=\"same\",\n",
    "input_shape=input_into_first_layer))\n",
    "model10.add(Activation(\"relu\"))\n",
    "model10.add(BatchNormalization(axis=chanDim))\n",
    "model10.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model10.add(Dropout(0.25))\n",
    " \n",
    "# (CONV => RELU => POOL) * 2\n",
    "model10.add(SeparableConv2D(64, (3, 3), padding=\"same\"))\n",
    "model10.add(Activation(\"relu\"))\n",
    "model10.add(BatchNormalization(axis=chanDim))\n",
    "model10.add(SeparableConv2D(64, (3, 3), padding=\"same\"))\n",
    "model10.add(Activation(\"relu\"))\n",
    "model10.add(BatchNormalization(axis=chanDim))\n",
    "model10.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model10.add(Dropout(0.25))\n",
    " \n",
    "# (CONV => RELU => POOL) * 3\n",
    "model10.add(SeparableConv2D(128, (3, 3), padding=\"same\"))\n",
    "model10.add(Activation(\"relu\"))\n",
    "model10.add(BatchNormalization(axis=chanDim))\n",
    "model10.add(SeparableConv2D(128, (3, 3), padding=\"same\"))\n",
    "model10.add(Activation(\"relu\"))\n",
    "model10.add(BatchNormalization(axis=chanDim))\n",
    "model10.add(SeparableConv2D(128, (3, 3), padding=\"same\"))\n",
    "model10.add(Activation(\"relu\"))\n",
    "model10.add(BatchNormalization(axis=chanDim))\n",
    "model10.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model10.add(Dropout(0.25))\n",
    "\n",
    "model10.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model10.add(Dense(256, activation ='relu'))\n",
    "model10.add(BatchNormalization())\n",
    "\n",
    "model10.add(Dropout(0.5))\n",
    "model10.add(Dense(1, activation ='sigmoid'))\n",
    "# model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "model10.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['binary_accuracy',recall,precision, f1])\n",
    "\n",
    "model10.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T21:26:00.185522Z",
     "start_time": "2019-04-02T18:42:09.747717Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3126/3126 [==============================] - 497s 159ms/step - loss: 1.1251 - binary_accuracy: 0.5719 - recall: 0.9391 - precision: 0.5467 - f1: 0.6710\n",
      "Epoch 2/20\n",
      "3126/3126 [==============================] - 487s 156ms/step - loss: 1.0566 - binary_accuracy: 0.5953 - recall: 0.9487 - precision: 0.5616 - f1: 0.6869\n",
      "Epoch 3/20\n",
      "3126/3126 [==============================] - 501s 160ms/step - loss: 0.9826 - binary_accuracy: 0.6423 - recall: 0.9493 - precision: 0.5931 - f1: 0.7108\n",
      "Epoch 4/20\n",
      "3126/3126 [==============================] - 484s 155ms/step - loss: 0.9710 - binary_accuracy: 0.6496 - recall: 0.9510 - precision: 0.5980 - f1: 0.7153\n",
      "Epoch 5/20\n",
      "3126/3126 [==============================] - 482s 154ms/step - loss: 0.9550 - binary_accuracy: 0.6574 - recall: 0.9547 - precision: 0.6040 - f1: 0.7206\n",
      "Epoch 6/20\n",
      "3126/3126 [==============================] - 486s 155ms/step - loss: 0.9601 - binary_accuracy: 0.6497 - recall: 0.9520 - precision: 0.5982 - f1: 0.7161\n",
      "Epoch 7/20\n",
      "3126/3126 [==============================] - 496s 159ms/step - loss: 0.9506 - binary_accuracy: 0.6571 - recall: 0.9535 - precision: 0.6037 - f1: 0.7210\n",
      "Epoch 8/20\n",
      "3126/3126 [==============================] - 493s 158ms/step - loss: 0.9838 - binary_accuracy: 0.6386 - recall: 0.9546 - precision: 0.5895 - f1: 0.7095\n",
      "Epoch 9/20\n",
      "3126/3126 [==============================] - 494s 158ms/step - loss: 0.9573 - binary_accuracy: 0.6523 - recall: 0.9553 - precision: 0.5982 - f1: 0.7172\n",
      "Epoch 10/20\n",
      "3126/3126 [==============================] - 496s 159ms/step - loss: 0.9469 - binary_accuracy: 0.6591 - recall: 0.9523 - precision: 0.6045 - f1: 0.7205\n",
      "Epoch 11/20\n",
      "3126/3126 [==============================] - 494s 158ms/step - loss: 0.9408 - binary_accuracy: 0.6595 - recall: 0.9534 - precision: 0.6055 - f1: 0.7215\n",
      "Epoch 12/20\n",
      "3126/3126 [==============================] - 493s 158ms/step - loss: 0.9375 - binary_accuracy: 0.6638 - recall: 0.9517 - precision: 0.6097 - f1: 0.7241\n",
      "Epoch 13/20\n",
      "3126/3126 [==============================] - 501s 160ms/step - loss: 0.9162 - binary_accuracy: 0.6778 - recall: 0.9549 - precision: 0.6190 - f1: 0.7322\n",
      "Epoch 14/20\n",
      "3126/3126 [==============================] - 500s 160ms/step - loss: 0.9007 - binary_accuracy: 0.6841 - recall: 0.9526 - precision: 0.6248 - f1: 0.7356\n",
      "Epoch 15/20\n",
      "3126/3126 [==============================] - 487s 156ms/step - loss: 0.9271 - binary_accuracy: 0.6685 - recall: 0.9555 - precision: 0.6128 - f1: 0.7276\n",
      "Epoch 16/20\n",
      "3126/3126 [==============================] - 490s 157ms/step - loss: 0.9236 - binary_accuracy: 0.6724 - recall: 0.9525 - precision: 0.6164 - f1: 0.7292\n",
      "Epoch 17/20\n",
      "3126/3126 [==============================] - 487s 156ms/step - loss: 0.9166 - binary_accuracy: 0.6768 - recall: 0.9578 - precision: 0.6168 - f1: 0.7319\n",
      "Epoch 18/20\n",
      "3126/3126 [==============================] - 476s 152ms/step - loss: 0.9194 - binary_accuracy: 0.6740 - recall: 0.9552 - precision: 0.6163 - f1: 0.7304\n",
      "Epoch 19/20\n",
      "3126/3126 [==============================] - 482s 154ms/step - loss: 0.8998 - binary_accuracy: 0.6830 - recall: 0.9577 - precision: 0.6229 - f1: 0.7365\n",
      "Epoch 20/20\n",
      "3126/3126 [==============================] - 503s 161ms/step - loss: 0.8908 - binary_accuracy: 0.6912 - recall: 0.9581 - precision: 0.6281 - f1: 0.7401\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f0c49d0f28>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model10.fit_generator(\n",
    "        train_gen10,\n",
    "        steps_per_epoch=3126,\n",
    "        epochs=20,\n",
    "        class_weight = {0:1,\n",
    "                        1:3.5}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T21:46:06.010822Z",
     "start_time": "2019-04-02T21:45:01.164788Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5584337609514394,\n",
       " 0.7444017909691262,\n",
       " 0.9445523465587325,\n",
       " 0.6687764754412804,\n",
       " 0.7687074963244123]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model10.evaluate_generator(train_gen10, steps = len(train_gen10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T21:46:43.741708Z",
     "start_time": "2019-04-02T21:46:30.924610Z"
    },
    "run_control": {
     "marked": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5373099723359203,\n",
       " 0.7595907934486409,\n",
       " 0.9403087322211936,\n",
       " 0.6650428349709572,\n",
       " 0.7663180488149833]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model10.evaluate_generator(test_gen10, steps = len(test_gen10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class_mode=binary\n",
    "loss=binary_crossentropy\n",
    "outut layer: 1 sigmoid activation\n",
    "class_weight = {0:1,\n",
    "                        1:2.5}\n",
    "epoch 20\n",
    "150 x 150 images\n",
    "\n",
    "Architecture from: https://www.pyimagesearch.com/2019/02/18/breast-cancer-classification-with-keras-and-deep-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T03:50:33.596698Z",
     "start_time": "2019-04-03T03:50:33.250591Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3126 images belonging to 2 classes.\n",
      "Found 782 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "image_dimensions = (150,150)\n",
    "input_into_first_layer = (150,150,1)\n",
    "\n",
    "\n",
    "train_gen11 = ImageDataGenerator(rescale = 1./255, rotation_range = 45, horizontal_flip = True, vertical_flip = True)\n",
    "test_gen11 = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "# train_gen = im_gen.flow_from_directory(directory = '..\\Images\\All_images_in_classes', target_size=(50,50), color_mode='rgb', class_mode = 'categorical', batch_size =100, subset ='training')\n",
    "# test_gen = im_gen.flow_from_directory(directory = '..\\Images\\All_images_in_classes', target_size=(50,50), color_mode='rgb', class_mode = 'categorical', batch_size =100, subset = 'validation')\n",
    "\n",
    "train_gen11=train_gen11.flow_from_dataframe(dataframe=df_train, directory ='..\\Images\\All_Images', x_col='image_id', y_col='dx',target_size=image_dimensions, color_mode='grayscale', class_mode='binary', batch_size= batch_size)\n",
    "test_gen11= test_gen11.flow_from_dataframe(dataframe=df_test, directory ='..\\Images\\All_Images', x_col='image_id', y_col='dx',target_size=image_dimensions, color_mode='grayscale', class_mode='binary', batch_size= batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T03:50:34.203687Z",
     "start_time": "2019-04-03T03:50:34.198699Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0_not_cancer': 0, '1_cancer': 1}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gen11.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T03:50:38.768563Z",
     "start_time": "2019-04-03T03:50:35.261741Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\petra\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\petra\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "separable_conv2d_1 (Separabl (None, 150, 150, 32)      73        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 150, 150, 32)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 150, 150, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 75, 75, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 75, 75, 32)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_2 (Separabl (None, 75, 75, 64)        2400      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 75, 75, 64)        256       \n",
      "_________________________________________________________________\n",
      "separable_conv2d_3 (Separabl (None, 75, 75, 64)        4736      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 75, 75, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 37, 37, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 37, 37, 64)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_4 (Separabl (None, 37, 37, 128)       8896      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 37, 37, 128)       512       \n",
      "_________________________________________________________________\n",
      "separable_conv2d_5 (Separabl (None, 37, 37, 128)       17664     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 37, 37, 128)       512       \n",
      "_________________________________________________________________\n",
      "separable_conv2d_6 (Separabl (None, 37, 37, 128)       17664     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 37, 37, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 18, 18, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 18, 18, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 41472)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               10617088  \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 10,671,978\n",
      "Trainable params: 10,670,378\n",
      "Non-trainable params: 1,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# model9.add(Conv2D(32, (3, 3),input_shape=input_into_first_layer))\n",
    "# model9.add(Activation('relu'))\n",
    "# model9.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# model9.add(Conv2D(32, (3, 3),activation = 'relu'))\n",
    "# model9.add(MaxPooling2D(pool_size=(2, 2) ))\n",
    "\n",
    "# model9.add(Conv2D(64, (3, 3), activation ='relu'))\n",
    "# model9.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# model9.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "# model9.add(Dense(64, activation ='relu'))\n",
    "# # model.add(Dropout(0.5))\n",
    "# model9.add(Dense(1, activation ='sigmoid'))\n",
    "\n",
    "# model9.compile(loss='binary_crossentropy',\n",
    "#               optimizer='adam',\n",
    "#               metrics=['binary_accuracy',recall,precision, f1])\n",
    "\n",
    "# model9.summary()\n",
    "\n",
    "# CONV => RELU => POOL\n",
    "chanDim = -1\n",
    "\n",
    "model11 = Sequential()\n",
    "\n",
    "model11.add(SeparableConv2D(32, (3, 3), padding=\"same\",\n",
    "input_shape=input_into_first_layer))\n",
    "model11.add(Activation(\"relu\"))\n",
    "model11.add(BatchNormalization(axis=chanDim))\n",
    "model11.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model11.add(Dropout(0.25))\n",
    " \n",
    "# (CONV => RELU => POOL) * 2\n",
    "model11.add(SeparableConv2D(64, (3, 3), padding=\"same\"))\n",
    "model11.add(Activation(\"relu\"))\n",
    "model11.add(BatchNormalization(axis=chanDim))\n",
    "model11.add(SeparableConv2D(64, (3, 3), padding=\"same\"))\n",
    "model11.add(Activation(\"relu\"))\n",
    "model11.add(BatchNormalization(axis=chanDim))\n",
    "model11.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model11.add(Dropout(0.25))\n",
    " \n",
    "# (CONV => RELU => POOL) * 3\n",
    "model11.add(SeparableConv2D(128, (3, 3), padding=\"same\"))\n",
    "model11.add(Activation(\"relu\"))\n",
    "model11.add(BatchNormalization(axis=chanDim))\n",
    "model11.add(SeparableConv2D(128, (3, 3), padding=\"same\"))\n",
    "model11.add(Activation(\"relu\"))\n",
    "model11.add(BatchNormalization(axis=chanDim))\n",
    "model11.add(SeparableConv2D(128, (3, 3), padding=\"same\"))\n",
    "model11.add(Activation(\"relu\"))\n",
    "model11.add(BatchNormalization(axis=chanDim))\n",
    "model11.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model11.add(Dropout(0.25))\n",
    "\n",
    "model11.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model11.add(Dense(256, activation ='relu'))\n",
    "model11.add(BatchNormalization())\n",
    "\n",
    "model11.add(Dropout(0.5))\n",
    "model11.add(Dense(1, activation ='sigmoid'))\n",
    "# model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "model11.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['binary_accuracy',recall,precision, f1])\n",
    "\n",
    "model11.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T15:48:52.645325Z",
     "start_time": "2019-04-03T03:50:38.966535Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\petra\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/20\n",
      "3126/3126 [==============================] - 531s 170ms/step - loss: 0.9310 - binary_accuracy: 0.6446 - recall: 0.8955 - precision: 0.6025 - f1: 0.6992\n",
      "Epoch 2/20\n",
      "3126/3126 [==============================] - 475s 152ms/step - loss: 0.8595 - binary_accuracy: 0.6752 - recall: 0.9127 - precision: 0.6248 - f1: 0.7217\n",
      "Epoch 3/20\n",
      "3126/3126 [==============================] - 554s 177ms/step - loss: 0.8708 - binary_accuracy: 0.6649 - recall: 0.9128 - precision: 0.6160 - f1: 0.7156\n",
      "Epoch 4/20\n",
      "3126/3126 [==============================] - 595s 190ms/step - loss: 0.8297 - binary_accuracy: 0.6901 - recall: 0.9235 - precision: 0.6355 - f1: 0.7332\n",
      "Epoch 5/20\n",
      "3126/3126 [==============================] - 647s 207ms/step - loss: 0.8630 - binary_accuracy: 0.6668 - recall: 0.9246 - precision: 0.6146 - f1: 0.7186\n",
      "Epoch 6/20\n",
      "3126/3126 [==============================] - 523s 167ms/step - loss: 0.8498 - binary_accuracy: 0.6724 - recall: 0.9256 - precision: 0.6212 - f1: 0.7239\n",
      "Epoch 7/20\n",
      "3126/3126 [==============================] - 488s 156ms/step - loss: 0.9017 - binary_accuracy: 0.6340 - recall: 0.9227 - precision: 0.5909 - f1: 0.7000\n",
      "Epoch 8/20\n",
      "3126/3126 [==============================] - 482s 154ms/step - loss: 0.8411 - binary_accuracy: 0.6807 - recall: 0.9192 - precision: 0.6284 - f1: 0.7267\n",
      "Epoch 9/20\n",
      "3126/3126 [==============================] - 506s 162ms/step - loss: 0.8310 - binary_accuracy: 0.6833 - recall: 0.9256 - precision: 0.6284 - f1: 0.7289\n",
      "Epoch 10/20\n",
      "3126/3126 [==============================] - 510s 163ms/step - loss: 0.8376 - binary_accuracy: 0.6806 - recall: 0.9253 - precision: 0.6268 - f1: 0.7271\n",
      "Epoch 11/20\n",
      "3126/3126 [==============================] - 509s 163ms/step - loss: 0.8319 - binary_accuracy: 0.6829 - recall: 0.9264 - precision: 0.6280 - f1: 0.7293\n",
      "Epoch 12/20\n",
      "3126/3126 [==============================] - 1926s 616ms/step - loss: 0.8360 - binary_accuracy: 0.6831 - recall: 0.9234 - precision: 0.6292 - f1: 0.7289\n",
      "Epoch 13/20\n",
      "3126/3126 [==============================] - 32038s 10s/step - loss: 0.8295 - binary_accuracy: 0.6828 - recall: 0.9256 - precision: 0.6294 - f1: 0.7295\n",
      "Epoch 14/20\n",
      "3126/3126 [==============================] - 479s 153ms/step - loss: 0.8496 - binary_accuracy: 0.6702 - recall: 0.9275 - precision: 0.6187 - f1: 0.7224\n",
      "Epoch 15/20\n",
      "3126/3126 [==============================] - 481s 154ms/step - loss: 0.8428 - binary_accuracy: 0.6755 - recall: 0.9240 - precision: 0.6241 - f1: 0.7255\n",
      "Epoch 16/20\n",
      "3126/3126 [==============================] - 478s 153ms/step - loss: 0.7988 - binary_accuracy: 0.7064 - recall: 0.9276 - precision: 0.6483 - f1: 0.7430\n",
      "Epoch 17/20\n",
      "3126/3126 [==============================] - 473s 151ms/step - loss: 0.7993 - binary_accuracy: 0.7006 - recall: 0.9303 - precision: 0.6421 - f1: 0.7399\n",
      "Epoch 18/20\n",
      "3126/3126 [==============================] - 467s 149ms/step - loss: 0.7922 - binary_accuracy: 0.7090 - recall: 0.9293 - precision: 0.6499 - f1: 0.7454\n",
      "Epoch 19/20\n",
      "3126/3126 [==============================] - 465s 149ms/step - loss: 0.7828 - binary_accuracy: 0.7131 - recall: 0.9287 - precision: 0.6540 - f1: 0.7473\n",
      "Epoch 20/20\n",
      "3126/3126 [==============================] - 464s 148ms/step - loss: 0.7801 - binary_accuracy: 0.7148 - recall: 0.9323 - precision: 0.6548 - f1: 0.7507\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24f13d5dc50>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model11.fit_generator(\n",
    "        train_gen11,\n",
    "        steps_per_epoch=3126,\n",
    "        epochs=20,\n",
    "        class_weight = {0:1,\n",
    "                        1:2.5}\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
